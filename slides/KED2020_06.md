---
title: The ABC of computational Text Analysis
subtitle: "06: Learning Regular Expressions"
author: "Alex Flückiger"
institute: |
  | Faculty of Humanities and Social Sciences
  | University of Lucerne
date: "2 April 2020"
header-includes: \metroset{progressbar=frametitle,sectionpage=progressbar}
pandoc-latex-unlisted: [unlisted]
lang: en-US
from: markdown+emoji
---



## Recap last Lecture

- counting words
  - particular or all words
- preprocessing steps



::: notes

- 

:::

## Outline

- discussion assignment
- introduction regular expression :sparkles:

::: notes

- regular expression
- Verschiebung Zeitplan

:::



# Assignment #1

## Sorry,<br>this was too steep!{data-background=images/cliffs-of-moher.jpg}

<!-- https://www.reddit.com/r/EarthPorn/comments/3fhebq/the_cliffs_of_moher_ireland_oc_2560x1709/ -->



::: notes

- 2 Stunden bis zwei Arbeitstage

:::

## Feedback Assignment #1

[Example solution](https://github.com/aflueckiger/KED2020/blob/master/exercises/flueckiger_KED2020_ex_1_solutions.sh)

:::::::::::::: {.columns}

:::{.column}

 :thumbsup:

* great dedication
* creative solutions I didn't show

:::

:::{.column}

:triumph:

- make sure folder exists
  - check with `ls` or in GUI
- Home on Windows
  - `/mnt/c/Users/YOUR_WINDOWS_USERNAME/`
- use operators `>  >>  |` anytime
  - files don't need to preexist
- wildcard `*` saves you work
  - `*2015*.txt`





:::

::::::::::::::



::: notes

- kein individuelles Feedback via OLAT
  - Lösung bei allen mehr/weniger ok
- durchgehen von Musterlösungen
- Rückfrage: alle können persönliche Dateien finden via Finder?
  - Home in Windows unter speziellem Pfad

:::

## Review beyond the Shell  

:::::::::::::: {.columns }

:::{.column}

:man_facepalming:

- too brief to be clear
- missing parts
  - feedback, second task

:::

:::{.column}

:cold_sweat:

- `locate` didn't work

:::

::::::::::::::





## Writing runnable Scripts

#### Requirements

- use text editor, not Word
  - Mac: TextWrangler
  - Win: Notepad++
- no prompt, just commands
-  `#` precedes any non-commands
- file suffix `.sh`



The beauty of scripting is automation. :zap:




::: notes

- Ordner müssen existieren, um Dateien oder Unterordner darin erstellen zu können
- locate findet nicht alle Dateien auf macOS: https://stackoverflow.com/questions/15887431/locate-command-cant-find-anything-inside-documents-folder-on-mac
- Files müssen nicht vorher erstellt werden, bevor man reinschreibt mit >

:::



## Plan Assignment #2

- get/submit via OLAT
  - starting tonight
  - deadline 16. April 2020, 23:59

- use forum on OLAT
  - subscribe to get notifications
- ask friends for support, not solutions



## Questions{data-background=#3c70b5}

# Text as Pattern

## Generalized Pattern

**Problem :red_circle:**

How to find **any** email addresses in a document? 

```markdown
Please contact us via info@organization.org. 
For specific questions ask Mrs. Green (a.green@mail.com).
```



. . .



**Solution** :large_blue_circle: 

Writing a generalized pattern

```bash
[\w._-]+@[\w._-]+		# matches any valid email address
```

::: notes

- Patterns anhand von Problemstellung einführen
- kryptisch, aber beliebig expressive Beschreibungssprache

:::

## What are patterns for?

- finding
- extracting
- removing
- replacing

... any textual parts



## What is RegEx?

#### RegEx = Regular Expressions ~ Patterns

- fixed string of characters
  - word, phrases, dates etc.
- abstract, highly flexible expressions
  - `[Cc]o+l` &rarr; Col, col, Cool, coool ...
  - literal + meta-characters
- akin to regular languages



::: notes

- Literale = Zeichen steht für tatsächliches Zeichen
- Meta-Zeichen = Zeichen mit spezieller Bedeutung

:::

## Finding + Extracting

#### globally search for regular expression and print (grep)

- tool to filter to keep certain lines only
- allow extended regex patterns
  - use `grep -P` instead of  `grep`

```bash
grep -r				# search entire subfolder

grep 'yes'			# keep lines containing pattern (i.e. yes)
grep -i 'yes' 		# dito, ignore casing (i.e., Yes, yes, YES...)
grep -v 'noisy' 	# do NOT keep lines containing noisy

# prepare for counting by extracting raw match only
grep –o 'only' 	# print match only, not entire line
grep –h 'only' 	# suppress file name
```



::: notes

- Empfehlung: immer grep -P benutzen

:::

## Quantifiers

repeat preceding character *X* times

- `?` zero or one
- `+` one or more
- `*` zero or any number
- `{n}`, `{m,n}` a specified number of times

```bash
grep -Pr "Bundesrath?es"		# matches old and new spelling of
grep -Pr "aa+" 					# matches two or more "a"
grep -Pr "e{2}"					# match sequences of three vowels
```



Do not confuse regex with wildcards!



::: notes

- zuerst ein bisschen künstliche Beispiele
- in Regex beziehen sich Operatoren auf vorderes Zeichen, in Wildcard nicht

:::



## Character Sets

* `[...]` any of these character
  * any vowel: `[auoei]`
* `[^...]` any character but none of these
  * anything but the vowels: `[^auoei]`



```bash
# match the capitalized and non-capitalized form
grep -Pr '[Gg]rüne'

# match sequences of 3 vowels
grep -Pr [aeiou]{3}

# extract all bigrams (sequence of two words)
grep -Proshi '[a-z]+ [a-z]+'
```



## Special Symbols

* `.` any character (excl. newline)
* `\` escaping to match literal 
  * `\.` means the actual `.`, not "any symbol"
* `\w` any alpha-numeric character
  * same as `[A-Za-z0-9_]`
* `\s` any whitespace (space, newline, tab)
  * same as `[ \t\n]`



```bash
# match anything between brackets
grep -Pr '\(.*\)'
```



## The power of ...{data-background=#4d7e65} 

`.*` matches *any character any number of times*



## More complex Examples

```bash
# extract websites
grep -Pro "www\.\w+\.\w+"

# extract emails
grep -Pro "[\w._-]+@[\w._-]+" */*.txt
```



## Start simple, <br>add complexity {data-background=images/knitting.jpg}

<!-- https://wallpaperscraft.com/download/needles_thread_knitting_105073/2048x1365 -->



## Replacing + Removing

#### stream editor (sed)

- advanced find + replace using regex
  - `sed "s/WHAT/WITH/g" FILE`
-  `sed` replaces any sequence,  `tr` only single symbols



```bash
echo "hello" | sed "s/llo/y/g"	# replace "llo" with a "y"

# by setting the g flag in "s/llo/y/g",
# sed replaces all occurences, not only the first one
```



## Contextual Replacing 

- reuse match with grouping
  - `\1`  equals the expression inside first pair of parentheses
  - `\2`  expression of second pair
  - ...



```bash
# swap order of name (last first -> first last)
echo "Lastname Firstname" | sed -E "s/(.*) (.*)/\2 \1/"

# matching also supports grouping
# match any two digit pair
grep -Pr "(\d)\1(\d)\2"
```



## Something actually useful

#### combining regular expressions with frequency analysis

```bash
# count political areas by looking up words ending with "politik"
grep -Prioh '\w*politik' */*.txt | sort | uniq -c | sort -h

# count ideologies/concepts by looking up words ending with -ismus
grep -Prioh '\w*ismus' */*.txt | sort | uniq -c | sort -h
```



::: notes

- zeige Resources am Schluss der Präsentation

:::

## In-class: Exercises I{data-background=#3c70b5}

1. Update your local copy of the Github repository KED2020 with `git pull`.  Go to the party programmes in `materials/party_programmes/txt`.

2. Use `grep -P` to extract all uppercased words that are abbreviations in most cases (e.g., UNO, SVP, SP).

3. Use `grep -P` to extract words following any of these strings: `der die das`.

4. Do the self-check on the next slide.

5. Use `sed -E` to remove the table of content, the footer and the page number in the programme of the Green Party. Check the PDF to get a visual impression and test your regular expression with `grep -P` to see if you match the correct parts in the document.

   


## In-class: Self-Check{data-background=#3c70b5}

#### equivalent patterns

```bash
a+ == aa* 			# "a" once or more than once
a? == a|_ 			# "a" once or nothing
a{3} == aaa			# three "a"
a{2,3} == aa|aaa	# two or three "a"
[ab] == a|b			# "a" or "b"
\d == 0|1|2|3|4|5|6|7|8|9	#any digit
```

## In-class: Exercise II{data-background=#3c70b5}

1. Since you know about RegEx, we can use a more sophisticated tokenizer to split a text into words. What  is the difference between the old and new approach?  Test it and check the helper page with `man`.

   ```bash
   # new, improved approach
   cat text.txt | tr -sc "[a-zäöüA-ZÄÖÜ0-9-]" "\n"
   
   # old approach
   cat text.txt | tr ' ' '\n'	
   ```



## More Resources

#### required

- Ben Schmidt. 2019. Regular Expressions. [online](https://github.com/HumanitiesDataAnalysis/HDA19/blob/master/Handouts/01-regex.pdf)



<br>

#### highly recommended

- Nikolaj Lindberg. egrep for Linguists. [online](https://stts.se/eegrep_for_linguists/eegrep_for_linguists.pdf)

