---
title: The ABC of computational Text Analysis
subtitle: "08: Create your own Data Sets + Ethics"
author: "Alex Flückiger"
institute: |
  | Faculty of Humanities and Social Sciences
  | University of Lucerne
date: "23 April 2020"
header-includes: \metroset{progressbar=frametitle,sectionpage=progressbar}
pandoc-latex-unlisted: [unlisted]
lang: en-US
from: markdown+emoji
---



## Recap last Lecture

- cleaning with regular expression
- finding data sources



::: notes

- 

:::

## Outline

- feedback assignment #2
- your texts are your data :white_check_mark:
  - anything
  - from anytime
  - from anywhere
- care about ethics :see_no_evil::hear_no_evil::speak_no_evil: 

::: notes

- 

:::



# Assignment #2

## Feedback Assignment #2

[example solution](https://github.com/aflueckiger/KED2020/blob/master/exercises/exercise_2/flueckiger_KED2020_ex_2_solutions.sh)

- make patterns more general
  - date: `DD Month DDDD`
- keep it simple
  - name of month ~ any word ~ `\w+`
- avoid false positives with positional information 
  - start of line: `^`
- names are hard to extract
  - variation + inconsistency

<br>

:nerd_face: check the count of matches



::: notes

- posititv: besser gelöst, weniger Zeit gebraucht als übugn 1
- Zählen der matches, wenn Anzahl Metadaten bekannt
- tradeoff: generalisierung vs. spezifizität
  - so generell wie möglich, so spzezifisch wie nötig

:::

# Converting Documents

## {data-background=images/file_types.jpg}

<!-- https://www.studio-24-7.com/file-formats-and-their-uses-explained/ -->





::: notes

- extrem viele File-Typen
- wir beschäftigen uns nur mit gebräuchlichsten

:::



## A world for humans ...

***news, press releases, reports from organisations***



:::::::::::::: {.columns}

:::{.column width="50%"}

- digital documents
  - `pdf`, `docx`

:arrow_down:

**convert to `.txt`**

:::

:::{.column width="50%"}



- scans of (old) documents
  - `pdf`, `jpg`, `png`

:arrow_down:

**Optical Character Recognition (OCR) **

:::

:::::::::::::: 

:white_check_mark:

**machine-readable**



::: notes



:::





## Conversion of DOCX

#### use case: news articles from [Nexis](www.nexisuni.com)

```bash
# convert docx to txt
pandoc in.docx -t plain -o out.txt

### Install first with
brew install pandoc 	# macOS
sudo apt install pandoc # Ubuntu
```

:::::::::::::: {.columns}

:::{.column width="50%"}

- pandoc ~ file converter
- export articles as `docx` on Nexis

:::

:::{.column width="50%"}

![](images/nexis.png)

:::

::::::::::::::

## Conversion of digital PDF

#### use case: [Swiss party programmes](https://manifesto-project.wzb.eu/datasets)

```bash
pdftotext -nopgbrk -eol unix in.pdf

### Install first with
brew install poppler 			# macOS
sudo apt install poppler-utils 	# Ubuntu
```



::: notes

- Layout kann Extraktion erschweren
- für Häufigkeitsanalysen reichen Wörter

:::

## Optical Character Recognition (OCR)

:::::::::::::: {.columns}

:::{.column width="50%"}



- OCR ~ convert images into text
  - text from scans/images
  - handwriting + Fraktur texts
- language-specific models
- image quality determines text quality
- open-source software: `tesseract`



:::

:::{.column width="50%"}

![[Wikipedia](https://de.wikipedia.org/wiki/Texterkennung)](images/ocr.png)

:::

::::::::::::::





::: notes

- technisch Deep-Learning, nicht weiter von Bedeutung

- auch von Handy möglich, ohne teure Programmen

  

:::



## Conversion of digitalized PDF

#### use-case: TODO

1. extract image from PDF
2. run optical character regognition (OCR) on image

```bash
# convert pdf to tiff, control quality with parameters
convert -density 300 -depth 8 -strip -background white -alpha off \
file_in.pdf temp.tiff

# run OCR for German ("eng" for English)
tesseract -l deu temp.tiff file_out


### Install first with
brew install imagemagick			# macOS
sudo apt install imagemagick-6.q16	# Ubuntu
```



::: notes

- tesseract funktioniert für viele Bildformate
- Beispiel: Kassenbon fotografieren & mit Regex parsen

:::



## LifeHack: Make a PDF searchable {data-background=#4d7e65}

#### use case: scanned book chapters

```bash
# output searchable pdf instead of txt
convert -density 300 -depth 8 -strip -background white -alpha off \
file_in.pdf temp.tiff
tesseract -l deu temp.tiff file_out pdf
```



::: notes

- Output als PDF statt Text

:::





## Scraping PDFs

#### use case: [Swiss voting booklet](https://www.bk.admin.ch/bk/de/home/dokumentation/abstimmungsbuechlein.html)

- wget to download any files from the internet

```bash
# get single file
wget EXACT_URL

# get all linked pdf from a single webpage
wget --recursive --accept pdf -nH --cut-dirs=5 \
--ignore-case -w 1 -l 1 --directory-prefix=data \
https://www.bk.admin.ch/bk/de/home/dokumentation/abstimmungsbuechlein.html

# --accept FORMAT_OF_YOUR_INTEREST
```



::: notes

- Scraping von Blogs möglich über Python 
- Haupt-URL angeben, wo PDF verlinkt sind
- nicht auf alle Argumente eingehen

:::

## More Sources

* [Party Programmes across Europe](https://manifesto-project.wzb.eu/datasets)
* [Swiss voting booklets](https://www.bk.admin.ch/bk/de/home/dokumentation/abstimmungsbuechlein.html)
* [1 August speeches by Swiss Federal Councillors](https://www.admin.ch/gov/de/start/dokumentation/reden/ansprachen-zum-nationalfeiertag.html)
* [Nestlé Annual Reports](https://www.nestle.com/csv/performance/downloads)



:nerd_face: Any organization of your interest!





## Preprocessing → RegEx{data-background=#b5533c}

![](images/clean_data.png)



## Idea of Batch Processing

#### perform the same operation on many files

```bash
# loop over all txt files
for file in *.txt; do

	# rename each file
	mv $file new_$file

done
```



::: notes

Erklären von Loop und Variable

:::

## Batch OCR over all PDF

```bash
for FILEPATH in *.pdf; do 

	# convert pdf to image
    convert -density 300 $FILEPATH -depth 8 -strip \
    -background white -alpha off temp.tiff
    
    # define output name
    OUTFILE=${file%.docx} 
    
    # perform OCR on the tiff image
    tesseract -l deu temp.tiff $OUTFILE
    
    # remove the intermediate tiff image
    rm temp.tiff

done
```



::: notes

- nun alles da für Mini-Project, ausser wenn Lösung in Python
- 

:::

# Bias & Ethics

## Don't be a fool ... {data-background=#b5533c}

... be wise, think twice.



::: notes

- über Seminar hinaus Thema
  - Studien/Geschäftsmodelle, die daneben sind
  - Ungleichheit: Geschlecht, Ethnie, sozioökonomisch
  - automatisch Bewerbungen erfassen
- Ethik ist nicht abstrakt und gehört nicht nur in Philosophie
- nicht Begriff ist wichtig, sondern Denkart
  - nachdenken über Ausgangslage + Konsequenzen
- besseres Verständis = bessere Data Science
- bestenfalls: naiv, schlechtensfalls: anti-liberal/diskriminierend

:::



## Data = Digital Traces

- collecting, curating, preserving traces &rarr; uncover patterns
- data don’t disclose anything, you can speak with it though



## A long Tail of Bias

* data/archive holes

  * lost, uncollected
* noise in data

  * OCR errors, inconsistent spelling, non-content
* corpus curation

  * supposition that key-word indicates topic
* social context like economic pressure

<br>

:arrow_right: solution: reflect + tackle



::: notes

- z.B. Budgetkürzung oder Neuausrichtung --> Wegfall von Thema
- non-content elements
  - Metadaten, Kopfzeilen etc.

:::



## {data-background=#4d7e65} 

> Raw data is an oxymoron.
> <br>[@Gitelman2013]



## Data vs. Capta

> Differences in the etymological roots of the terms data and capta make the distinction between          constructivist and realist approaches clear. *Capta* is <span style="color:#b5533c">**"taken"**</span> actively while *data* is assumed to be a <span style="color:#b5533c">**"given"**</span> able to be recorded and observed. From this distinction, a world of differences arises. Humanistic inquiry acknowledges the situated, partial, and constitutive character of knowledge production, the recognition that <span style="color:#b5533c">**knowledge is constructed**</span>, *taken*, not simply given as a natural representation of pre-existing fact.
>
> [@Drucker2011]



## Key Principles

- Who has a voice in your data?
  - social context
- bigger is not necessarily better
  - more vs. more diverse data

* clean your data thoroughly
  * noisy vs. clean data



## {data-background=images/datahumanism.jpeg}

<!-- https://giorgialupi.com/data-humanism-my-manifesto-for-a-new-data-wold -->

## Data represents real life. {data-background=#4d7e65}



## In-class: Exercises I{data-background=#3c70b5}

1. Make sure that your local copy of the Github repository KED2020 is up-to-date with `git pull`.  Go to the party programmes in `materials/party_programmes/txt`.
2. Install the missing tools with the commands given the respective slides: `pandoc, imagemagick, poppler`
3. `wget` todos
4. Digest the commands. Test them. Check resources. Ask questions.
5. 

## Resources

#### Make a more sophisticated script for PDF conversion

- Erick Peirson. 2015. Tutorial: Text Extraction and OCR with Tesseract and ImageMagick - Methods in Digital and Computational Humanities - DigInG Confluence. [online](https://diging.atlassian.net/wiki/spaces/DCH/pages/5275668/Tutorial+Text+Extraction+and+OCR+with+Tesseract+and+ImageMagick)



## References